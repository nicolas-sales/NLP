{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "378a24ac-4d41-417f-80f9-4ae892e08889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c59ff5-b1a8-4bd8-8301-2cdfb2498283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f356772-8e84-4645-b12c-dbb4219226a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7e6aeb-1cb9-4bcd-b8f8-5ff7f6fbccaf",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c87faf2c-5034-4504-9f8f-9d8f62c20967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c34a791-f30c-4e09-a476-6adc4837d180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1 star', 'score': 0.551443874835968}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple d'analyse de sentiments\n",
    "pipe(\"Je suis énervé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef372030-9e57-4885-9478-fe76f7d0ca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.8128679394721985}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Je suis très heureux.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7856ca88-40ab-4ffd-b5e7-57a1c6feeb10",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1b72b37-0f84-4c0e-8521-19f97225952e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'apprends la science des données.\n"
     ]
    }
   ],
   "source": [
    "# Pipeline pour la traduction (Anglais vers Français par exemple)\n",
    "traducteur = pipeline('translation_en_to_fr', model='t5-base')\n",
    "\n",
    "# Traduction d'une phrase de l'anglais vers le français\n",
    "phrase_traduite = traducteur(\"I am learning Data Science.\")\n",
    "\n",
    "# Affichage de la phrase traduite\n",
    "print(phrase_traduite[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202709ac-b25a-443d-8df2-c74c59de3c86",
   "metadata": {},
   "source": [
    "# Generation de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdf47712-11f9-4fbe-a316-cae9b276a2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'apprentissage de la data science c'est aussi apprendre à utiliser des outils de data science . Le premier est un peu plus long , mais il est très agréable à lire . Il est donc important de bien choisir son matériel . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son équipement . Il est donc important de bien choisir son matériel de ski . Il est donc important de bien choisir son matériel de\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Chargement du tokenizer et du modèle pour la génération de texte\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"antoiloui/belgpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"antoiloui/belgpt2\")\n",
    "\n",
    "# Préparation des entrées pour la génération de texte, avec attention_mask\n",
    "inputs = tokenizer(\"L'apprentissage de la data science c'est\", return_tensors=\"pt\")\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Génération de texte en français en fournissant l'attention_mask et en définissant pad_token_id si nécessaire\n",
    "text_generation = model.generate(\n",
    "    input_ids=inputs['input_ids'],\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=200,\n",
    "    num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.eos_token_id  # Définir si nécessaire\n",
    ")\n",
    "\n",
    "# Affichage du texte généré\n",
    "print(tokenizer.decode(text_generation[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aff98fb-b9ea-4193-bd0e-e42ef33ac021",
   "metadata": {},
   "source": [
    "# Classification zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5677a-057a-4c75-9dc7-fe658f94f678",
   "metadata": {},
   "source": [
    "La classification à zero-shot fait référence à la capacité d'un modèle à classer correctement des textes dans des catégories sans avoir reçu d'exemples spécifiques lors de son entraînement.\r\n",
    "\r\n",
    "Le modèle utilise sa compréhension générale de la langue pour faire des hypothèses sur la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7c82ef3-8be9-4b9f-9e76-dc10f2c4ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "034a107d-4166-4d0a-8307-c30ab4f82543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': \"Cet article traite de l'importance de l'intelligence artificielle dans la société moderne.\",\n",
       " 'labels': ['technologie', 'politique', 'éducation', 'économie'],\n",
       " 'scores': [0.7246903777122498,\n",
       "  0.09451788663864136,\n",
       "  0.0943371132016182,\n",
       "  0.0864545926451683]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline pour la classification à zéro coup\n",
    "classify_zero_shot = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Exemple de classification à zéro coup en français\n",
    "classify_zero_shot(\n",
    "    \"Cet article traite de l'importance de l'intelligence artificielle dans la société moderne.\",\n",
    "    candidate_labels=[\"éducation\", \"politique\", \"technologie\", \"économie\"],\n",
    "    hypothesis_template=\"Cet article est sur {}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000024d-8c26-431f-a898-342350a1476d",
   "metadata": {},
   "source": [
    "La sequence est classée dans la classe 'technologie' avec un score de 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8307234c-0b6e-4442-83ff-9f92880b54dd",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c6ae649-22ec-4949-8ebd-81a6a9091846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['je', 'suis', 'ravi', 'de', 'd', \"'\", 'apprend', '##re', 'sur', 'le', 'sujet', 'de', 'l', \"'\", 'intelligence', 'arti', '##fici', '##elle', '.']\n",
      "Identifiants de Tokens: [101, 10149, 41496, 73681, 10102, 146, 112, 60011, 10247, 10344, 10130, 32733, 10102, 154, 112, 19334, 33005, 61463, 14205, 119, 102]\n",
      "Résultat de l'analyse de sentiment: [{'label': '5 stars', 'score': 0.4703008830547333}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Nom du modèle pré-entraîné que vous souhaitez utiliser\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "\n",
    "# Chargement du tokenizer et du modèle pour la classification de séquences\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Création d'une pipeline de classification de sentiment\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Exemple de texte à analyser\n",
    "texte = \"Je suis ravi de d'apprendre sur le sujet de l'intelligence artificielle.\"\n",
    "\n",
    "# Tokenisation du texte\n",
    "tokens = tokenizer.tokenize(texte)\n",
    "input_ids = tokenizer.encode(texte)\n",
    "\n",
    "# Affichage des tokens et des identifiants de tokens\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Identifiants de Tokens:\", input_ids)\n",
    "\n",
    "# Exécution de la pipeline de classification de sentiment sur le texte\n",
    "resultat = classifier(texte)\n",
    "\n",
    "# Affichage du résultat de l'analyse de sentiment\n",
    "print(\"Résultat de l'analyse de sentiment:\", resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21425127-5141-41c8-8e45-e3dfd5f5850d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Je', 'suis', 'ra', '##vi', 'de', 'd', \"'\", 'apprend', '##re', 'sur', 'le', 'sujet', 'de', 'l', \"'\", 'intelligence', 'arti', '##ficie', '##lle', '.']\n"
     ]
    }
   ],
   "source": [
    "# Nom du modèle pré-entraîné que vous souhaitez utiliser\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# Chargement du tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Exemple de texte à tokeniser\n",
    "sequence = \"Je suis ravi de d'apprendre sur le sujet de l'intelligence artificielle.\"\n",
    "\n",
    "# Tokenisation de la séquence\n",
    "tokens = tokenizer.tokenize(sequence)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86dbe6ac-e021-4eff-9c66-ae6e9b6d9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifiants de Tokens: [13796, 49301, 11859, 11310, 10104, 172, 112, 62131, 10246, 10326, 10141, 34949, 10104, 180, 112, 30151, 46118, 72138, 11270, 119]\n"
     ]
    }
   ],
   "source": [
    "# Conversion des tokens en identifiants de tokens\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(\"Identifiants de Tokens:\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e436bb2-1393-4939-8b14-4180b53329ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Séquence décodée: Je suis ravi de d ' apprendre sur le sujet de l ' intelligence artificielle.\n"
     ]
    }
   ],
   "source": [
    "# Décodage des identifiants de tokens pour récupérer la séquence\n",
    "decoded_sequence = tokenizer.decode(token_ids)\n",
    "print(\"Séquence décodée:\", decoded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1f874-b3e1-4015-a4b4-354568f9df83",
   "metadata": {},
   "source": [
    "# Faire un résumé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42ed3acd-8a43-4b42-b8d1-2c84daa90028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'intelligence artificielle est un domaine de l'informatique. Les algorithmes d'apprentissage automatique permettent aux ordinateurs de s'entraîner sur des donn\n"
     ]
    }
   ],
   "source": [
    "# Charger la pipeline de résumé avec le modèle BART\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Exemple de texte long à résumer\n",
    "text = \"\"\"\n",
    "L'intelligence artificielle est un domaine de l'informatique qui met l'accent sur la création de machines capables de travailler et de réagir comme des humains. Certains des exemples de travail dans ce domaine sont l'apprentissage automatique, où les ordinateurs, les logiciels et les appareils effectuent via des algorithmes des tâches de manière intelligente. Les algorithmes d'apprentissage automatique, qui sont au cœur de l'intelligence artificielle, permettent aux ordinateurs de s'entraîner sur des données fournies puis d'utiliser ces données pour prédire et prendre des décisions basées sur de nouvelles données. Les avantages de l'intelligence artificielle sont nombreux et peuvent avoir un impact significatif sur les secteurs où la précision et la cohérence sont cruciales.\n",
    "\"\"\"\n",
    "\n",
    "# Effectuer le résumé\n",
    "summary = summarizer(text, max_length=50, min_length=30, do_sample=False)\n",
    "\n",
    "# Afficher le résumé\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c746023-2334-4bfe-aa2a-1fa392153694",
   "metadata": {},
   "source": [
    "# Description d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22d7afc7-ad6f-40d5-aacf-fb0b46ee9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a235929b-4160-4af6-b2ee-6944569f316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_legende_en_francais(chemin_image):\n",
    "    \"\"\"\n",
    "    Génère une légende pour une image donnée en anglais et la traduit en français.\n",
    "\n",
    "    :param chemin_image: Le chemin vers l'image pour laquelle générer une légende.\n",
    "    :type chemin_image: str\n",
    "    :return: La légende traduite en français.\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialiser la pipeline de légendage d'image\n",
    "    pipeline_legende_image = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "    # Initialiser la pipeline de traduction de l'anglais vers le français\n",
    "    pipeline_traduction = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "    # Génération de la légende en anglais\n",
    "    resultats_legende = pipeline_legende_image(chemin_image)\n",
    "    legende_anglaise = resultats_legende[0]['generated_text']\n",
    "\n",
    "    # Traduction de la légende en français\n",
    "    legende_francaise = pipeline_traduction(legende_anglaise, max_length=512)\n",
    "    texte_francais = legende_francaise[0]['translation_text']\n",
    "\n",
    "    return texte_francais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3fd66907-49eb-4c88-adae-06e0a516a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un homme grimpant sur une montagne la nuit avec la lune en arrière-plan\n"
     ]
    }
   ],
   "source": [
    "legende_francaise = generer_legende_en_francais(r\"C:\\Users\\nicolas.sales\\Desktop\\climb.jpg\")\n",
    "print(legende_francaise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de277b8b-e02c-47a9-b079-54f8331ad32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un graphique indiquant le nombre de personnes qui se trouvent dans chaque pays\n"
     ]
    }
   ],
   "source": [
    "legende_francaise2 = generer_legende_en_francais(r\"C:\\Users\\nicolas.sales\\Desktop\\Europcar\\Star Rating\\Evolution of star rating.png\")\n",
    "print(legende_francaise2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
